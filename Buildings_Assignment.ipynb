{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Input Files for Repast Models\n",
    "\n",
    "This notebook generates the input files for the agents in the Repast4py-Models project. \n",
    "\n",
    "It takes some spatial input data, and some census data to model the population flows between census blocks and OSM buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from bisect import bisect\n",
    "from itertools import repeat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input files\n",
    "buildings_path = './buildings_assignment_input_files/buildings_CT/bldgs_ct.shp'\n",
    "ct_path = './buildings_assignment_input_files/ffx_county_city_ct/ffx_county_city_ct.shp'\n",
    "flows_path = './buildings_assignment_input_files/commuting_flows_gt.csv'\n",
    "\n",
    "# Output files\n",
    "building_ffx = './repast4py/input/input_buildings_ffx_2.csv'\n",
    "input_agents_ffx = './repast4py/input/input_agents_ffx_2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the buildings\n",
    "Needs to read the OSM shapefile, reproject the coords, and rename some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = gpd.read_file(buildings_path)\n",
    "buildings = buildings.reset_index()\n",
    "buildings = buildings.rename(columns={\"index\":\"building_id\"})\n",
    "\n",
    "# Strange Projection to reproject to... Why not WGS84 or something more specific to location. \n",
    "buildings['x_centroid'] = np.floor(buildings['geometry'].to_crs(epsg=32610).centroid.x).astype(np.int64)\n",
    "buildings['y_centroid'] = np.floor(buildings['geometry'].to_crs(epsg=32610).centroid.y).astype(np.int64)\n",
    "\n",
    "buildings = buildings[['building_id','x_centroid','y_centroid','predicted','GEOID10']]\n",
    "buildings = buildings.rename(columns={\"predicted\":\"building_type\", \"GEOID10\":\"ct_id\"})\n",
    "buildings['ct_id'] = buildings['ct_id'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### building types: 0 - non-residential; 1 - residential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.to_csv(building_ffx, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Buildings per Census Tract?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'ct_id': buildings['ct_id'].drop_duplicates().reset_index(drop=True),\n",
    "     'res_count': [0] * buildings['ct_id'].nunique(), \n",
    "     'non_res_count': [0] * buildings['ct_id'].nunique()}\n",
    "\n",
    "buildings_per_ct = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_per_ct['res_count']=buildings_per_ct['ct_id'].map(buildings[buildings['building_type'] == 1].groupby('ct_id').count()['building_type'])\n",
    "buildings_per_ct['non_res_count']=buildings_per_ct['ct_id'].map(buildings[buildings['building_type'] == 0].groupby('ct_id').count()['building_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_per_ct = buildings_per_ct.fillna(0)\n",
    "buildings_per_ct['res_count'] = buildings_per_ct['res_count'].astype(np.int64)\n",
    "buildings_per_ct['non_res_count'] = buildings_per_ct['non_res_count'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Simulated Work <> Home trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_2010 = gpd.read_file(ct_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GEOID10       object\n",
       "geometry    geometry\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_2010.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_2010['GEOID10'] = ct_2010['GEOID10'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34366, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commuting_flows = pd.read_csv(flows_path)\n",
    "commuting_flows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34366, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commuting_flows = commuting_flows[commuting_flows['h_geoid'].isin(ct_2010['GEOID10'])]\n",
    "commuting_flows = commuting_flows[commuting_flows['w_geoid'].isin(ct_2010['GEOID10'])]\n",
    "commuting_flows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33757, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commuting_flows = commuting_flows[commuting_flows['h_geoid'].isin\n",
    "                                  (buildings_per_ct[buildings_per_ct['res_count'] != 0]['ct_id'])]\n",
    "commuting_flows = commuting_flows[commuting_flows['w_geoid'].isin\n",
    "                                  (buildings_per_ct[buildings_per_ct['non_res_count'] != 0]['ct_id'])]\n",
    "commuting_flows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_per_ct = buildings_per_ct.copy()\n",
    "pop_per_ct = pop_per_ct.rename(columns={'res_count': 'res_pop', 'non_res_count': 'work_pop'})\n",
    "pop_per_ct['res_pop'].values[:] = 0\n",
    "pop_per_ct['work_pop'].values[:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_per_ct['res_pop'] = pop_per_ct['ct_id'].map(\n",
    "    commuting_flows.groupby('h_geoid').sum()['count'])\n",
    "pop_per_ct['work_pop'] = pop_per_ct['ct_id'].map(\n",
    "    commuting_flows.groupby('w_geoid').sum()['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_per_ct = pop_per_ct.fillna(0)\n",
    "pop_per_ct['res_pop'] = pop_per_ct['res_pop'].astype(np.int64)\n",
    "pop_per_ct['work_pop'] = pop_per_ct['work_pop'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping through census tracks to generate work/home links?\n",
    "Not sure what's going on here. Must this be in a loop? Seems to run rather slow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic population generation: 2-pass weighted probability for selecting work census tracts\n",
    "home_id = []\n",
    "work_id = []\n",
    "for index, row in pop_per_ct.iterrows():\n",
    "    home_id.extend(buildings[(buildings['ct_id'] == row['ct_id']) & \n",
    "              (buildings['building_type'] == 1)]['building_id'].sample(row['res_pop'], \n",
    "                                                                       replace=True).values.tolist())\n",
    "\n",
    "    work_flows = commuting_flows[commuting_flows['h_geoid'] == row['ct_id']]\n",
    "    idx_list = []\n",
    "    size = work_flows['count'].sum()\n",
    "    arr = (work_flows['count']/size).cumsum().to_numpy()\n",
    "\n",
    "    idx_list = [bisect(arr,round(random(), 8)) \n",
    "                    for _ in repeat(None, size)] \n",
    "    w_ids = work_flows.reset_index()['w_geoid'].iloc[idx_list].values.tolist()\n",
    "\n",
    "    work_id += [buildings[(buildings['ct_id'] == w_id) & \n",
    "                            (buildings['building_type'] == 0)]['building_id'].sample\n",
    "                            (1).reset_index().at[0,'building_id']\n",
    "                            for w_id in w_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_agents = pd.DataFrame(\n",
    "    {'home_id': home_id,\n",
    "     'work_id': work_id,\n",
    "    })\n",
    "input_agents = input_agents.reset_index().rename(columns={'index': 'agent_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_agents.to_csv(input_agents_ffx, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_id</th>\n",
       "      <th>home_id</th>\n",
       "      <th>work_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11384</td>\n",
       "      <td>31035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11384</td>\n",
       "      <td>137774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11397</td>\n",
       "      <td>8786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11395</td>\n",
       "      <td>13355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11395</td>\n",
       "      <td>4826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258431</th>\n",
       "      <td>258431</td>\n",
       "      <td>91220</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258432</th>\n",
       "      <td>258432</td>\n",
       "      <td>91214</td>\n",
       "      <td>7362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258433</th>\n",
       "      <td>258433</td>\n",
       "      <td>91222</td>\n",
       "      <td>2544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258434</th>\n",
       "      <td>258434</td>\n",
       "      <td>91214</td>\n",
       "      <td>1719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258435</th>\n",
       "      <td>258435</td>\n",
       "      <td>91216</td>\n",
       "      <td>11352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258436 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        agent_id  home_id  work_id\n",
       "0              0    11384    31035\n",
       "1              1    11384   137774\n",
       "2              2    11397     8786\n",
       "3              3    11395    13355\n",
       "4              4    11395     4826\n",
       "...          ...      ...      ...\n",
       "258431    258431    91220      307\n",
       "258432    258432    91214     7362\n",
       "258433    258433    91222     2544\n",
       "258434    258434    91214     1719\n",
       "258435    258435    91216    11352\n",
       "\n",
       "[258436 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
